#  Remote Weather Access - Client/server solution for distributed weather networks
#   Copyright (C) 2013-2023 Ralf Rettig (info@personalfme.de)
#
#   This program is free software: you can redistribute it and/or modify
#   it under the terms of the GNU Affero General Public License as
#   published by the Free Software Foundation, either version 3 of the
#   License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU Affero General Public License for more details.
#
#   You should have received a copy of the GNU Affero General Public License
#   along with this program.  If not, see <https://www.gnu.org/licenses/>.

image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/python:3.11.13-bookworm

include:
  - template: 'Workflows/MergeRequest-Pipelines.gitlab-ci.yml'

variables:
  GCP_REGION: ${GCP_REGION_ID}
  GCP_FRONTEND_REGION: ${GCP_FRONTEND_REGION_ID}
  GCP_FRONTEND_ARTIFACT_REGISTRY: ${GCP_FRONTEND_REGION}-docker.pkg.dev
  GCP_BACKEND_ARTIFACT_REGISTRY: ${GCP_REGION}-docker.pkg.dev
  BACKEND_PORT: 443
  FRONTEND_SERVICE_NAME: frontend-${CI_COMMIT_REF_SLUG}
  BACKEND_SERVICE_NAME: backend-${CI_COMMIT_REF_SLUG}
  EXPORTER_SERVICE_NAME: exporter-${CI_COMMIT_REF_SLUG}
  PIP_CACHE_DIR: ${CI_PROJECT_DIR}/.cache/pip
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""
  BRAND_NAME: ${BRAND_NAME}
  EXPORTER_SCHEDULER_JOB_NAME: export-csv-job-${CI_COMMIT_REF_SLUG}
  EXPORTER_BUCKET_ID: weather-export-data-
  EXPORTER_CSV_FILE_DIR: /tmp
  FRONTEND_BUCKET_ID: frontend-static-
  CLOUD_BUILD_BUCKET_ID: cloud-build-
  SECRET_DJANGO_SECRET_KEY_NAME: django-secret-key
  FRONTEND_ADDRESS: ${FRONTEND_ADDRESS}
  FRONTEND_ENV_PATH: /app/frontend/environments/.frontend.production.env

default:
  tags:
    - docker

.python_prepare: &python_prepare
  - python3 --version
  - pip3 install virtualenv
  - virtualenv venv
  - source venv/bin/activate

.install_gettext: &install_gettext
  - apt-get --allow-releaseinfo-change update
  - apt-get install -qq -y gettext

.gcp_cloud_login: &gcp_cloud_login
  - gcloud auth activate-service-account --key-file ${GOOGLE_APPLICATION_CREDENTIALS}
  - gcloud config set project ${GCP_PROJECT_ID}

.gcp_cloud_run_deploy: &gcp_cloud_run_deploy
  - envsubst < ./deployment/google_cloud_run/${TIER}_with_variables.yaml > ${TIER}.yaml
  - gcloud beta run services replace ${TIER}.yaml
    --region=${CURR_GCP_REGION}
    --platform=managed
  - service_name=${TIER^^}_SERVICE_NAME
  - gcloud run services add-iam-policy-binding ${!service_name}
    --region=${CURR_GCP_REGION}
    --platform=managed
    --member="${CLOUD_RUN_INVOKER}"
    --role="roles/run.invoker"
  - export ${TIER^^}_URL=$(gcloud run services describe ${!service_name}
    --region=${CURR_GCP_REGION}
    --platform=managed
    --format='value(status.url)')

.gcp_django_migration: &gcp_django_migration
  - CLOUD_BUILD_BUCKET=$(gcloud storage ls | grep ${CLOUD_BUILD_BUCKET_ID})
  - CLOUD_BUILD_SOURCE_STAGING_DIR=${CLOUD_BUILD_BUCKET}source
  - gcloud builds submit --gcs-source-staging-dir=${CLOUD_BUILD_SOURCE_STAGING_DIR} --config=./deployment/google_cloud_build/cloudmigrate.yaml --substitutions=_GCP_ARTIFACT_REGISTRY=${GCP_FRONTEND_ARTIFACT_REGISTRY},_DOCKER_REPOSITORY=frontend,_FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME},_CI_COMMIT_SHA=${CI_COMMIT_SHA},_SQL_DATABASE_ID=${SQL_DATABASE_ID},_SECRET_DJANGO_SECRET_KEY_NAME=${SECRET_DJANGO_SECRET_KEY_NAME},_FRONTEND_ENV_PATH=${FRONTEND_ENV_PATH},_FRONTEND_ADDRESS=${FRONTEND_ADDRESS},_EXPORTER_BUCKET=${EXPORTER_BUCKET},_FRONTEND_BUCKET=${FRONTEND_BUCKET},_BACKEND_URL_BASE=${BACKEND_URL_BASE},_BACKEND_PORT=${BACKEND_PORT},_BRAND_NAME="${BRAND_NAME}"

.gcp_cloud_scheduler_job: &gcp_cloud_scheduler_job
  - existing_scheduler_jobs=$(gcloud scheduler jobs list --format 'value(name)' --filter "name ~ ${EXPORTER_SCHEDULER_JOB_NAME}" --location ${GCP_REGION})
  - num_scheduler_jobs=$(wc -w <<< "$existing_scheduler_jobs")
  - if [ $num_scheduler_jobs != 0 ]; then gcloud scheduler jobs delete ${EXPORTER_SCHEDULER_JOB_NAME} --quiet  --location ${GCP_REGION} ; fi
  - gcloud scheduler jobs create http ${EXPORTER_SCHEDULER_JOB_NAME}
    --uri="${EXPORTER_URL}/upload"
    --http-method=POST
    --description="Exports PC-Wetterstation compatible CSV files of the weather data"
    --schedule="7 0 * * *"
    --time-zone="Europe/Stockholm"
    --oidc-service-account-email=${EXPORTER_SERVICE_ACCOUNT_NAME}
    --max-retry-attempts=1
    --location ${GCP_REGION}

.gcp_backend_deploy: &gcp_backend_deploy
  - TIER=backend
  - export SQL_DATABASE_ID=${GCP_REGION}:$(gcloud sql instances list --format 'value(name)')
  - num_databases=$(wc -w <<< "$SQL_DATABASE_ID")
  - if [ $num_databases != 1 ]; then echo "ERROR, not exactly one database in GCP-project"; exit 1; fi
  - CLOUD_RUN_INVOKER="allUsers"
  - CURR_GCP_REGION=${GCP_REGION}
  - export GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
  - export DOCKER_REPOSITORY=backend
  - *gcp_cloud_run_deploy
  - export BACKEND_URL_BASE=$(basename ${BACKEND_URL})

.gcp_frontend_deploy: &gcp_frontend_deploy
  - TIER=frontend
  - export FRONTEND_BUCKET=$(gcloud storage ls | grep ${FRONTEND_BUCKET_ID})
  - export EXPORTER_BUCKET=$(gcloud storage ls | grep ${EXPORTER_BUCKET_ID})
  - CLOUD_RUN_INVOKER="allUsers"
  - CURR_GCP_REGION=${GCP_FRONTEND_REGION}
  - export GCP_ARTIFACT_REGISTRY=${GCP_FRONTEND_ARTIFACT_REGISTRY}
  - export DOCKER_REPOSITORY=frontend
  - *gcp_django_migration
  - *gcp_cloud_run_deploy
  - echo "FRONTEND_URL=${FRONTEND_URL}" > frontend_deploy.env

.gcp_exporter_deploy: &gcp_exporter_deploy
  - TIER=exporter
  - CLOUD_RUN_INVOKER="serviceAccount:${EXPORTER_SERVICE_ACCOUNT_NAME}"
  - CURR_GCP_REGION=${GCP_REGION}
  - export GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
  - export DOCKER_REPOSITORY=backend
  - *gcp_cloud_run_deploy
  - *gcp_cloud_scheduler_job

.gcp_deploy: &gcp_deploy
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:531.0.0
  resource_group: deploy
  script:
    - *gcp_cloud_login
    - *install_gettext
    - *gcp_backend_deploy
    - *gcp_frontend_deploy
    - *gcp_exporter_deploy
  artifacts:
    reports:
      dotenv: frontend_deploy.env

.gcp_build_image: &gcp_build_image
  - gcloud auth activate-service-account --key-file ${GOOGLE_APPLICATION_CREDENTIALS}
  - gcloud config set project ${GCP_PROJECT_ID}
  - gcloud auth configure-docker ${GCP_ARTIFACT_REGISTRY}
  - docker build .
    --file=Dockerfile.${DOCKER_FILE_ENDING}
    -t ${GCP_ARTIFACT_REGISTRY}/${GCP_PROJECT_ID}/${DOCKER_REPOSITORY}/${SERVICE_NAME}:${CI_COMMIT_SHA}
    -t ${GCP_ARTIFACT_REGISTRY}/${GCP_PROJECT_ID}/${DOCKER_REPOSITORY}/${SERVICE_NAME}:latest
    --build-arg BUILDKIT_INLINE_CACHE=1
    --cache-from ${GCP_ARTIFACT_REGISTRY}/${GCP_PROJECT_ID}/${DOCKER_REPOSITORY}/${SERVICE_NAME}:latest
  - docker push --all-tags ${GCP_ARTIFACT_REGISTRY}/${GCP_PROJECT_ID}/${DOCKER_REPOSITORY}/${SERVICE_NAME}

.gcp_image_delete: &gcp_image_delete
  - gcloud artifacts docker images delete ${GCP_ARTIFACT_REGISTRY}/${GCP_PROJECT_ID}/${DOCKER_REPOSITORY}/${SERVICE_NAME}
    --delete-tags

.gcp_cloud_run_delete: &gcp_cloud_run_delete
  - gcloud run services delete ${SERVICE_NAME}
    --region=${REGION_ID}
    --platform=managed
    --quiet

.gcp_delete: &gcp_delete
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:531.0.0
  script:
    - *gcp_cloud_login
    - gcloud scheduler jobs delete ${EXPORTER_SCHEDULER_JOB_NAME} --quiet --location ${GCP_REGION}
    - SERVICE_NAME=${FRONTEND_SERVICE_NAME}
    - GCP_ARTIFACT_REGISTRY=${GCP_FRONTEND_ARTIFACT_REGISTRY}
    - DOCKER_REPOSITORY=frontend
    - REGION_ID=${GCP_FRONTEND_REGION}
    - *gcp_cloud_run_delete
    - *gcp_image_delete
    - SERVICE_NAME=${BACKEND_SERVICE_NAME}
    - GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
    - DOCKER_REPOSITORY=backend
    - REGION_ID=${GCP_REGION}
    - *gcp_cloud_run_delete
    - *gcp_image_delete
    - SERVICE_NAME=${EXPORTER_SERVICE_NAME}
    - GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
    - DOCKER_REPOSITORY=backend
    - REGION_ID=${GCP_REGION}
    - *gcp_cloud_run_delete
    - *gcp_image_delete

.copy_text_files: &copy_text_files
  - mkdir frontend/text_content
  - cp ${DATA_PROTECTION_POLICY_HTML_FILE} frontend/django_frontend/weatherpage/templates/weatherpage/policy.html
  - cp ${IMPRESS_HTML_FILE} frontend/django_frontend/weatherpage/templates/weatherpage/impress.html

.publish_test_artifacts: &publish_test_artifacts
  when: always
  reports:
    junit: report.xml

before_script:
  - if [ ${CI_COMMIT_REF_NAME} == master ];
    then source deployment/environments/.production.env;
    else source deployment/environments/.testing.env;
    fi
  - export FRONTEND_SERVICE_ACCOUNT_NAME=weather-frontend@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export BACKEND_SERVICE_ACCOUNT_NAME=weather-backend@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export EXPORTER_SERVICE_ACCOUNT_NAME=weather-exporter@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME:0:63}
  - export FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME%-}
  - export BACKEND_SERVICE_NAME=${BACKEND_SERVICE_NAME:0:63}
  - export BACKEND_SERVICE_NAME=${BACKEND_SERVICE_NAME%-}
  - export EXPORTER_SERVICE_NAME=${EXPORTER_SERVICE_NAME:0:63}
  - export EXPORTER_SERVICE_NAME=${EXPORTER_SERVICE_NAME%-}

stages:
  - test
  - build containers
  - deploy review
  - cleanup review
  - deploy production

unittests backend:
  stage: test
  cache:
    key: backend
    paths:
      - .cache/pip
      - venv/
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/postgres:13.21-alpine
      alias: postgres
  before_script:
    - *python_prepare
    - pip3 install -r backend/requirements.txt
    - pip3 install -r backend/dev-requirements.txt
  variables:
    POSTGRES_DB: postgres
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: passwd
    POSTGRES_TEST_URL: postgres  # the URL provided by the service
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/backend
    - pytest backend/tests/unit_tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests frontend:
  stage: test
  cache:
    key: frontend
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r frontend/requirements.txt
    - pip3 install -r frontend/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/frontend
    - pytest frontend/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests exporter:
  stage: test
  cache:
    key: exporter
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r export/requirements.txt
    - pip3 install -r export/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/export
    - pytest export/tests/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests client:
  stage: test
  cache:
    key: client
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r client/requirements.txt
    - pip3 install -r client/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/client
    - pytest client/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

build backend:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:531.0.0
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:28.3.2-dind
      alias: docker
  script:
    - export SERVICE_NAME=${BACKEND_SERVICE_NAME}
    - export GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
    - export DOCKER_REPOSITORY=backend
    - *gcp_build_image
  variables:
    DOCKER_FILE_ENDING: backend

build frontend:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:531.0.0
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:28.3.2-dind
      alias: docker
  script:
    - export SERVICE_NAME=${FRONTEND_SERVICE_NAME}
    - export GCP_ARTIFACT_REGISTRY=${GCP_FRONTEND_ARTIFACT_REGISTRY}
    - export DOCKER_REPOSITORY=frontend
    - *copy_text_files
    - *gcp_build_image
  variables:
    DOCKER_FILE_ENDING: frontend

build exporter:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:531.0.0
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:28.3.2-dind
      alias: docker
  script:
    - export SERVICE_NAME=${EXPORTER_SERVICE_NAME}
    - export GCP_ARTIFACT_REGISTRY=${GCP_BACKEND_ARTIFACT_REGISTRY}
    - export DOCKER_REPOSITORY=backend
    - *gcp_build_image
  variables:
    DOCKER_FILE_ENDING: export

deploy review:
  stage: deploy review
  <<: *gcp_deploy
  environment:
    name: review/${CI_COMMIT_REF_NAME}
    url: $FRONTEND_URL
    on_stop: stop review
  rules:
    - if: '$CI_MERGE_REQUEST_ID || $CI_COMMIT_BRANCH != "master"'

stop review:
  stage: cleanup review
  resource_group: review
  dependencies:
    - deploy review
  <<: *gcp_delete
  environment:
    name: review/${CI_COMMIT_REF_NAME}
    action: stop
  rules:
    - if: '$CI_MERGE_REQUEST_ID || $CI_COMMIT_BRANCH != "master"'
      when: manual
      allow_failure: true

deploy production:
  stage: deploy production
  <<: *gcp_deploy
  environment:
    name: production
    url: $FRONTEND_URL
  only:
    - master
