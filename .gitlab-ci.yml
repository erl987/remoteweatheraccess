#  Remote Weather Access - Client/server solution for distributed weather networks
#   Copyright (C) 2013-2023 Ralf Rettig (info@personalfme.de)
#
#   This program is free software: you can redistribute it and/or modify
#   it under the terms of the GNU Affero General Public License as
#   published by the Free Software Foundation, either version 3 of the
#   License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU Affero General Public License for more details.
#
#   You should have received a copy of the GNU Affero General Public License
#   along with this program.  If not, see <https://www.gnu.org/licenses/>.

image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/python:3.11.6-bookworm

include:
  - template: 'Workflows/MergeRequest-Pipelines.gitlab-ci.yml'

variables:
  GCP_REGION: ${GCP_REGION_ID}
  GCP_FRONTEND_REGION: ${GCP_FRONTEND_REGION_ID}
  GCP_CONTAINER_REGISTRY: ${GCP_CONTAINER_REGISTRY}
  BACKEND_PORT: 443
  FRONTEND_SERVICE_NAME: frontend-${CI_COMMIT_REF_SLUG}
  BACKEND_SERVICE_NAME: backend-${CI_COMMIT_REF_SLUG}
  EXPORTER_SERVICE_NAME: exporter-${CI_COMMIT_REF_SLUG}
  PIP_CACHE_DIR: ${CI_PROJECT_DIR}/.cache/pip
  DOCKER_TLS_CERTDIR: "/certs"
  BRAND_NAME: ${BRAND_NAME}
  EXPORTER_SCHEDULER_JOB_NAME: export-csv-job-${CI_COMMIT_REF_SLUG}
  EXPORTER_BUCKET_ID: weather-export-data-
  EXPORTER_CSV_FILE_DIR: /tmp
  FRONTEND_BUCKET_ID: frontend-static-
  FRONTEND_SETTINGS_SECRET_NAME: frontend-settings
  FRONTEND_ADDRESS: ${FRONTEND_ADDRESS}

default:
  tags:
    - docker

.python_prepare: &python_prepare
  - python3 --version
  - pip3 install virtualenv
  - virtualenv venv
  - source venv/bin/activate

.install_gettext: &install_gettext
  - apt-get --allow-releaseinfo-change update
  - apt-get install -qq -y gettext

.gcp_docker_registry_login: &gcp_docker_registry_login
  - docker login --username _json_key --password-stdin https://${GCP_CONTAINER_REGISTRY} < ${GOOGLE_APPLICATION_CREDENTIALS}

.gcp_cloud_login: &gcp_cloud_login
  - gcloud auth activate-service-account --key-file ${GOOGLE_APPLICATION_CREDENTIALS}
  - gcloud config set project ${GCP_PROJECT_ID}

.gcp_cloud_run_deploy: &gcp_cloud_run_deploy
  - envsubst < ./deployment/google_cloud_run/${TIER}_with_variables.yaml > ${TIER}.yaml
  - gcloud beta run services replace ${TIER}.yaml
    --region=${CURR_GCP_REGION}
    --platform=managed
  - service_name=${TIER^^}_SERVICE_NAME
  - gcloud run services add-iam-policy-binding ${!service_name}
    --region=${CURR_GCP_REGION}
    --platform=managed
    --member="${CLOUD_RUN_INVOKER}"
    --role="roles/run.invoker"
  - export ${TIER^^}_URL=$(gcloud run services describe ${!service_name}
    --region=${CURR_GCP_REGION}
    --platform=managed
    --format='value(status.url)')

.gcp_django_migration: &gcp_django_migration
  - gcloud builds submit --config=./deployment/google_cloud_build/cloudmigrate.yaml --substitutions=_GCP_CONTAINER_REGISTRY=${GCP_CONTAINER_REGISTRY},_FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME},_CI_COMMIT_SHA=${CI_COMMIT_SHA},_SQL_DATABASE_ID=${SQL_DATABASE_ID},_SETTINGS_SECRET_NAME=${FRONTEND_SETTINGS_SECRET_NAME},_FRONTEND_BUCKET=${FRONTEND_BUCKET},_BACKEND_URL_BASE=${BACKEND_URL_BASE},_BACKEND_PORT=${BACKEND_PORT},_BRAND_NAME="${BRAND_NAME}"

.gcp_upload_environment_to_secret_manager: &gcp_upload_environment_to_secret_manager
  - printf "$(cat ./frontend/environments/.frontend.production.env)" "$(< /dev/urandom tr -cd '[:graph:]'| tr  -d '\\' | head -c 232; echo)" "${FRONTEND_ADDRESS}" "${EXPORTER_BUCKET}" | gcloud secrets versions add frontend-settings --data-file=-

.gcp_cloud_scheduler_job: &gcp_cloud_scheduler_job
  - existing_scheduler_jobs=$(gcloud scheduler jobs list --format 'value(name)' --filter "name ~ ${EXPORTER_SCHEDULER_JOB_NAME}" --location ${GCP_REGION})
  - num_scheduler_jobs=$(wc -w <<< "$existing_scheduler_jobs")
  - if [ $num_scheduler_jobs != 0 ]; then gcloud scheduler jobs delete ${EXPORTER_SCHEDULER_JOB_NAME} --quiet  --location ${GCP_REGION} ; fi
  - gcloud scheduler jobs create http ${EXPORTER_SCHEDULER_JOB_NAME}
    --uri="${EXPORTER_URL}/upload"
    --http-method=POST
    --description="Exports PC-Wetterstation compatible CSV files of the weather data"
    --schedule="7 0 * * *"
    --time-zone="Europe/Stockholm"
    --oidc-service-account-email=${EXPORTER_SERVICE_ACCOUNT_NAME}
    --max-retry-attempts=1
    --location ${GCP_REGION}

.gcp_deploy: &gcp_deploy
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:455.0.0
  resource_group: deploy
  script:
    - *gcp_cloud_login
    - *install_gettext
    - export SQL_DATABASE_ID=${GCP_REGION}:$(gcloud sql instances list --format 'value(name)')
    - num_databases=$(wc -w <<< "$SQL_DATABASE_ID")
    - if [ $num_databases != 1 ]; then echo "ERROR, not exactly one database in GCP-project"; exit 1; fi
    - TIER=backend
    - CLOUD_RUN_INVOKER="allUsers"
    - CURR_GCP_REGION=${GCP_REGION}
    - *gcp_cloud_run_deploy
    - export BACKEND_URL_BASE=$(basename ${BACKEND_URL})
    - TIER=frontend
    - export FRONTEND_BUCKET=$(gcloud storage ls | grep ${FRONTEND_BUCKET_ID})
    - export EXPORTER_BUCKET=$(gcloud storage ls | grep ${EXPORTER_BUCKET_ID})
    - CLOUD_RUN_INVOKER="allUsers"
    - CURR_GCP_REGION=${GCP_FRONTEND_REGION}
    - *gcp_upload_environment_to_secret_manager
    - *gcp_django_migration
    - *gcp_cloud_run_deploy
    - echo "FRONTEND_URL=${FRONTEND_URL}" > frontend_deploy.env
    - TIER=exporter
    - CLOUD_RUN_INVOKER="serviceAccount:${EXPORTER_SERVICE_ACCOUNT_NAME}"
    - CURR_GCP_REGION=${GCP_REGION}
    - *gcp_cloud_run_deploy
    - *gcp_cloud_scheduler_job

  artifacts:
    reports:
      dotenv: frontend_deploy.env

.gcp_delete_containers: &gcp_delete_containers
  - DIGESTS=$(gcloud container images list-tags ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${IMAGE_NAME}
    --format 'value(digest)')
  - for DIGEST in $DIGESTS;
    do
    gcloud container images delete ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${IMAGE_NAME}@sha256:${DIGEST}
    --force-delete-tags
    --quiet;
    done

.copy_text_files: &copy_text_files
  - mkdir frontend/text_content
  - cp ${DATA_PROTECTION_POLICY_HTML_FILE} frontend/django_frontend/weatherpage/templates/weatherpage/policy.html
  - cp ${IMPRESS_HTML_FILE} frontend/django_frontend/weatherpage/templates/weatherpage/impress.html

.publish_test_artifacts: &publish_test_artifacts
  when: always
  reports:
    junit: report.xml

before_script:
  - if [ ${CI_COMMIT_REF_NAME} == master ];
    then source deployment/environments/.production.env;
    else source deployment/environments/.testing.env;
    fi
  - export FRONTEND_SERVICE_ACCOUNT_NAME=weather-frontend@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export BACKEND_SERVICE_ACCOUNT_NAME=weather-backend@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export EXPORTER_SERVICE_ACCOUNT_NAME=weather-exporter@${GCP_PROJECT_ID}.iam.gserviceaccount.com
  - export FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME:0:63}
  - export FRONTEND_SERVICE_NAME=${FRONTEND_SERVICE_NAME%-}
  - export BACKEND_SERVICE_NAME=${BACKEND_SERVICE_NAME:0:63}
  - export BACKEND_SERVICE_NAME=${BACKEND_SERVICE_NAME%-}
  - export EXPORTER_SERVICE_NAME=${EXPORTER_SERVICE_NAME:0:63}
  - export EXPORTER_SERVICE_NAME=${EXPORTER_SERVICE_NAME%-}

stages:
  - test
  - build containers
  - deploy review
  - cleanup review
  - deploy production

unittests backend:
  stage: test
  cache:
    key: backend
    paths:
      - .cache/pip
      - venv/
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/postgres:13.10-alpine
      alias: postgres
  before_script:
    - *python_prepare
    - pip3 install -r backend/requirements.txt
    - pip3 install -r backend/dev-requirements.txt
  variables:
    POSTGRES_DB: postgres
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: passwd
    POSTGRES_TEST_URL: postgres  # the URL provided by the service
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/backend
    - pytest backend/tests/unit_tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests frontend:
  stage: test
  cache:
    key: frontend
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r frontend/requirements.txt
    - pip3 install -r frontend/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/frontend
    - pytest frontend/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests exporter:
  stage: test
  cache:
    key: exporter
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r export/requirements.txt
    - pip3 install -r export/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/export
    - pytest export/tests/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

unittests client:
  stage: test
  cache:
    key: client
    paths:
      - .cache/pip
      - venv/
  before_script:
    - *python_prepare
    - pip3 install -r client/requirements.txt
    - pip3 install -r client/dev-requirements.txt
  script:
    - export PYTHONPATH=${CI_PROJECT_DIR}/client
    - pytest client/tests --junitxml=report.xml
  artifacts:
    <<: *publish_test_artifacts

build backend:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7-dind
      alias: docker
  script:
    - *gcp_docker_registry_login
    - docker build .
      --file=./Dockerfile.backend
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${BACKEND_SERVICE_NAME}:${CI_COMMIT_SHA}
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${BACKEND_SERVICE_NAME}:latest
      --build-arg BUILDKIT_INLINE_CACHE=1
      --cache-from ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${BACKEND_SERVICE_NAME}:latest
    - docker push --all-tags ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${BACKEND_SERVICE_NAME}

build frontend:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7-dind
      alias: docker
  script:
    - *copy_text_files
    - *gcp_docker_registry_login
    - docker build .
      --file=./Dockerfile.frontend
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${FRONTEND_SERVICE_NAME}:${CI_COMMIT_SHA}
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${FRONTEND_SERVICE_NAME}:latest
      --build-arg BUILDKIT_INLINE_CACHE=1
      --cache-from ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${FRONTEND_SERVICE_NAME}:latest
    - docker push --all-tags ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${FRONTEND_SERVICE_NAME}

build exporter:
  stage: build containers
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7
  services:
    - name: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/docker:24.0.7-dind
      alias: docker
  script:
    - *gcp_docker_registry_login
    - docker build .
      --file=./Dockerfile.export
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${EXPORTER_SERVICE_NAME}:${CI_COMMIT_SHA}
      -t ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${EXPORTER_SERVICE_NAME}:latest
      --build-arg BUILDKIT_INLINE_CACHE=1
      --cache-from ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${EXPORTER_SERVICE_NAME}:latest
    - docker push --all-tags ${GCP_CONTAINER_REGISTRY}/${GCP_PROJECT_ID}/${EXPORTER_SERVICE_NAME}

deploy review:
  stage: deploy review
  <<: *gcp_deploy
  environment:
    name: review/${CI_COMMIT_REF_NAME}
    url: $FRONTEND_URL
    on_stop: stop review
  rules:
    - if: '$CI_MERGE_REQUEST_ID || $CI_COMMIT_BRANCH != "master"'

stop review:
  stage: cleanup review
  resource_group: review
  dependencies:
    - deploy review
  image: ${CI_DEPENDENCY_PROXY_GROUP_IMAGE_PREFIX}/google/cloud-sdk:455.0.0
  script:
    - *gcp_cloud_login
    - gcloud scheduler jobs delete ${EXPORTER_SCHEDULER_JOB_NAME} --quiet --location ${GCP_REGION}
    - gcloud run services delete ${FRONTEND_SERVICE_NAME}
      --region=${GCP_FRONTEND_REGION}
      --platform=managed
      --quiet
    - gcloud run services delete ${BACKEND_SERVICE_NAME}
      --region=${GCP_REGION}
      --platform=managed
      --quiet
    - gcloud run services delete ${EXPORTER_SERVICE_NAME}
      --region=${GCP_REGION}
      --platform=managed
      --quiet
    - IMAGE_NAME=${FRONTEND_SERVICE_NAME}
    - *gcp_delete_containers
    - IMAGE_NAME=${BACKEND_SERVICE_NAME}
    - *gcp_delete_containers
    - IMAGE_NAME=${EXPORTER_SERVICE_NAME}
    - *gcp_delete_containers
  environment:
    name: review/${CI_COMMIT_REF_NAME}
    action: stop
  rules:
    - if: '$CI_MERGE_REQUEST_ID || $CI_COMMIT_BRANCH != "master"'
      when: manual
      allow_failure: true

deploy production:
  stage: deploy production
  <<: *gcp_deploy
  environment:
    name: production
    url: $FRONTEND_URL
  only:
    - master
